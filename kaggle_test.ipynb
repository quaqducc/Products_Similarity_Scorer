{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kaggle Test: Product Similarity (NICE)\n",
        "\n",
        "Notebook này dùng để test repo Product_Similarity trên Kaggle.\n",
        "- Tự phát hiện repo và dữ liệu từ ` /kaggle/input `.\n",
        "- Hỗ trợ 2 chế độ: không dùng model (chỉ prompt + retriever) và dùng model HF cục bộ.\n",
        "- Có thể build lại `nice_chunks.json` từ `data_nice_cls` nếu thiếu.\n",
        "- Hỗ trợ chạy đơn lẻ và chạy batch từ file CSV.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths: adapt names to your uploaded Kaggle Datasets\n",
        "import os, sys, json, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# CHANGE THESE if your dataset names are different\n",
        "REPO_DS_NAME = \"product-similarity-repo\"   # dataset containing the repo (code files)\n",
        "DATA_DS_NAME = \"product-similarity-data\"   # dataset containing data/ and/or data_nice_cls/\n",
        "\n",
        "# Kaggle input base\n",
        "KAGGLE_INPUT = Path(\"/kaggle/input\")\n",
        "\n",
        "# Locate mount points\n",
        "repo_root = None\n",
        "for p in KAGGLE_INPUT.glob(f\"{REPO_DS_NAME}*\"):\n",
        "    if (p / \"product_similarity\" / \"prompt.py\").exists():\n",
        "        repo_root = p\n",
        "        break\n",
        "\n",
        "if repo_root is None:\n",
        "    raise RuntimeError(\"Không tìm thấy repo dataset. Đảm bảo bạn đã thêm Input Dataset cho repo.\")\n",
        "\n",
        "# Add repo to sys.path\n",
        "sys.path.insert(0, str(repo_root))\n",
        "\n",
        "# Prepare working directory in /kaggle/working\n",
        "work_dir = Path(\"/kaggle/working/product_similarity_work\")\n",
        "work_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy repo files into working dir so we can run/modify locally if needed\n",
        "shutil.copytree(repo_root, work_dir / \"repo\", dirs_exist_ok=True)\n",
        "code_root = work_dir / \"repo\"\n",
        "print(\"Repo root:\", code_root)\n",
        "\n",
        "# Locate data dataset (optional if you only want to run no-model without data)\n",
        "data_root = None\n",
        "for p in KAGGLE_INPUT.glob(f\"{DATA_DS_NAME}*\"):\n",
        "    # Accept if contains data/ or data_nice_cls/\n",
        "    if (p / \"data\").exists() or (p / \"data_nice_cls\").exists():\n",
        "        data_root = p\n",
        "        break\n",
        "\n",
        "print(\"Data root:\", data_root)\n",
        "\n",
        "# Link/copy data into working repo structure\n",
        "(target_data := code_root / \"data\").mkdir(parents=True, exist_ok=True)\n",
        "(target_cls := code_root / \"data_nice_cls\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if data_root is not None:\n",
        "    if (data_root / \"data\").exists():\n",
        "        shutil.copytree(data_root / \"data\", target_data, dirs_exist_ok=True)\n",
        "    if (data_root / \"data_nice_cls\").exists():\n",
        "        shutil.copytree(data_root / \"data_nice_cls\", target_cls, dirs_exist_ok=True)\n",
        "\n",
        "print(\"Prepared data at:\", target_data, target_cls)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure importable package\n",
        "import importlib\n",
        "pkg_path = code_root / \"product_similarity\"\n",
        "assert (pkg_path / \"__init__.py\").exists(), \"Missing package files in repo dataset!\"\n",
        "\n",
        "# Put working repo to sys.path first\n",
        "import sys\n",
        "sys.path.insert(0, str(code_root))\n",
        "\n",
        "product_similarity = importlib.import_module(\"product_similarity\")\n",
        "print(\"Loaded product_similarity version:\", getattr(product_similarity, \"__version__\", \"unknown\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build nice_chunks.json if missing\n",
        "from pathlib import Path\n",
        "\n",
        "nice_path = code_root / \"data\" / \"nice_chunks.json\"\n",
        "if not nice_path.exists():\n",
        "    print(\"nice_chunks.json missing -> attempt to build from data_nice_cls\")\n",
        "    tools_script = code_root / \"tools\" / \"merge_nice_cls.py\"\n",
        "    if not tools_script.exists():\n",
        "        raise RuntimeError(\"merge_nice_cls.py not found in repo/tools\")\n",
        "    import runpy\n",
        "    runpy.run_path(str(tools_script))\n",
        "else:\n",
        "    print(\"Found:\", nice_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Toggle: use model or not\n",
        "USE_MODEL = False  # set True to use HF model id below\n",
        "MODEL_ID = \"google/flan-t5-base\"  # change model as needed\n",
        "DEVICE = -1  # -1 CPU, 0 GPU\n",
        "\n",
        "# Optional: provide known NICE class numbers for p1/p2\n",
        "CLASS_1 = None  # e.g., \"3\"\n",
        "CLASS_2 = None  # e.g., \"16\"\n",
        "\n",
        "from product_similarity.pipeline import run_similarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single-run example\n",
        "p1 = \"Make-up preparations\"\n",
        "p2 = \"Tissues of paper for removing make-up\"\n",
        "\n",
        "res = run_similarity(\n",
        "    p1,\n",
        "    p2,\n",
        "    class_1=CLASS_1,\n",
        "    class_2=CLASS_2,\n",
        "    model_name=(MODEL_ID if USE_MODEL else None),\n",
        "    device=DEVICE,\n",
        ")\n",
        "\n",
        "# Show compact summary\n",
        "print(\"Scores:\", res[\"scores\"])  # may be None values if USE_MODEL=False\n",
        "print(\"Contexts:\")\n",
        "for c in res[\"contexts\"]:\n",
        "    print(\"-\", c.split(\"\\n\")[0])\n",
        "\n",
        "# Truncated prompt preview\n",
        "print(\"\\nPrompt preview:\\n\", res[\"prompt\"][:600], \"...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch evaluation from CSV (optional)\n",
        "# Expect CSV with headers: p1,p2[,class1,class2]\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Change this path if your data CSV is elsewhere inside the data dataset\n",
        "csv_path = code_root / \"data\" / \"100_samples.csv\"\n",
        "if not csv_path.exists():\n",
        "    print(\"CSV not found:\", csv_path)\n",
        "else:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    # Try to normalize columns\n",
        "    rename_map = {}\n",
        "    if df.columns[0] not in (\"p1\", \"P1\"):\n",
        "        rename_map[df.columns[0]] = \"p1\"\n",
        "    if df.columns[1] not in (\"p2\", \"P2\"):\n",
        "        rename_map[df.columns[1]] = \"p2\"\n",
        "    df = df.rename(columns=rename_map)\n",
        "    print(\"Loaded\", len(df), \"rows\")\n",
        "\n",
        "    out_rows = []\n",
        "    for i, row in df.iterrows():\n",
        "        p1 = str(row.get(\"p1\", row.iloc[0]))\n",
        "        p2 = str(row.get(\"p2\", row.iloc[1]))\n",
        "        c1 = row.get(\"class1\", CLASS_1)\n",
        "        c2 = row.get(\"class2\", CLASS_2)\n",
        "        res = run_similarity(\n",
        "            p1,\n",
        "            p2,\n",
        "            class_1=c1,\n",
        "            class_2=c2,\n",
        "            model_name=(MODEL_ID if USE_MODEL else None),\n",
        "            device=DEVICE,\n",
        "        )\n",
        "        out_rows.append({\n",
        "            \"p1\": p1,\n",
        "            \"p2\": p2,\n",
        "            \"class1\": c1,\n",
        "            \"class2\": c2,\n",
        "            \"nature\": res[\"scores\"].get(\"nature\"),\n",
        "            \"purpose\": res[\"scores\"].get(\"purpose\"),\n",
        "            \"overall\": res[\"scores\"].get(\"overall\"),\n",
        "        })\n",
        "    out_df = pd.DataFrame(out_rows)\n",
        "    out_path = Path(\"/kaggle/working/batch_results.csv\")\n",
        "    out_df.to_csv(out_path, index=False)\n",
        "    print(\"Saved:\", out_path)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

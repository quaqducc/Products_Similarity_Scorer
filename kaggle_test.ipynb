{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Test: Product Similarity (NICE)\n",
    "\n",
    "Notebook nÃ y dÃ¹ng Ä‘á»ƒ test repo Product_Similarity trÃªn Kaggle.\n",
    "- Tá»± phÃ¡t hiá»‡n repo vÃ  dá»¯ liá»‡u tá»« ` /kaggle/input `.\n",
    "- Há»— trá»£ 2 cháº¿ Ä‘á»™: khÃ´ng dÃ¹ng model (chá»‰ prompt + retriever) vÃ  dÃ¹ng model HF cá»¥c bá»™.\n",
    "- CÃ³ thá»ƒ build láº¡i `nice_chunks.json` tá»« `data_nice_cls` náº¿u thiáº¿u.\n",
    "- Há»— trá»£ cháº¡y Ä‘Æ¡n láº» vÃ  cháº¡y batch tá»« file CSV.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T14:16:09.584148Z",
     "iopub.status.busy": "2025-10-15T14:16:09.583921Z",
     "iopub.status.idle": "2025-10-15T14:16:09.705440Z",
     "shell.execute_reply": "2025-10-15T14:16:09.704698Z",
     "shell.execute_reply.started": "2025-10-15T14:16:09.584130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths: adapt names to your uploaded Kaggle Datasets\n",
    "import os, sys, json, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# CHANGE THESE if your dataset names are different\n",
    "REPO_DS_NAME = \"product-similarity-scorer\"   # dataset containing the repo (code files)\n",
    "DATA_DS_NAME = \"products-similarity-scorer-data\"   # dataset containing data/ and/or data_nice_cls/\n",
    "\n",
    "# Kaggle input base\n",
    "KAGGLE_INPUT = Path(\"/kaggle/input\")\n",
    "\n",
    "# Locate mount points\n",
    "repo_root = None\n",
    "for p in KAGGLE_INPUT.glob(f\"{REPO_DS_NAME}*\"):\n",
    "    if (p / \"product_similarity\" / \"prompt.py\").exists():\n",
    "        repo_root = p\n",
    "        break\n",
    "\n",
    "if repo_root is None:\n",
    "    raise RuntimeError(\"KhÃ´ng tÃ¬m tháº¥y repo dataset. Äáº£m báº£o báº¡n Ä‘Ã£ thÃªm Input Dataset cho repo.\")\n",
    "\n",
    "# Add repo to sys.path\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Prepare working directory in /kaggle/working\n",
    "work_dir = Path(\"/kaggle/working/product_similarity_work\")\n",
    "work_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy repo files into working dir so we can run/modify locally if needed\n",
    "shutil.copytree(repo_root, work_dir / \"repo\", dirs_exist_ok=True)\n",
    "code_root = work_dir / \"repo\"\n",
    "print(\"Repo root:\", code_root)\n",
    "\n",
    "# Locate data dataset (optional if you only want to run no-model without data)\n",
    "data_root = Path(KAGGLE_INPUT / DATA_DS_NAME)\n",
    "\n",
    "print(\"Data root:\", data_root)\n",
    "\n",
    "# Link/copy data into working repo structure\n",
    "(target_data := code_root / \"data\").mkdir(parents=True, exist_ok=True)\n",
    "# (target_cls := code_root / \"data_nice_cls\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if data_root is not None:\n",
    "    shutil.copytree(data_root, target_data, dirs_exist_ok=True)\n",
    "    # print(\"-\" * 20)\n",
    "    # print(f\"ðŸ“ CÃ¡c file trong thÆ° má»¥c Ä‘Ã­ch '{target_data}':\")\n",
    "    # for root, dirs, files in os.walk(target_data):\n",
    "    #     for name in files:\n",
    "    #         # Táº¡o Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§ vÃ  in ra\n",
    "    #         file_path = os.path.join(root, name)\n",
    "    #         print(file_path)\n",
    "    # print(\"-\" * 20)\n",
    "        \n",
    "    # if (data_root / \"data_nice_cls\").exists():\n",
    "    #     shutil.copytree(data_root / \"data_nice_cls\", target_cls, dirs_exist_ok=True)\n",
    "\n",
    "print(\"Prepared data at:\", target_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T14:16:09.706715Z",
     "iopub.status.busy": "2025-10-15T14:16:09.706428Z",
     "iopub.status.idle": "2025-10-15T14:16:09.719068Z",
     "shell.execute_reply": "2025-10-15T14:16:09.718325Z",
     "shell.execute_reply.started": "2025-10-15T14:16:09.706688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure importable package\n",
    "import importlib\n",
    "pkg_path = code_root / \"product_similarity\"\n",
    "assert (pkg_path / \"__init__.py\").exists(), \"Missing package files in repo dataset!\"\n",
    "\n",
    "# Put working repo to sys.path first\n",
    "import sys\n",
    "sys.path.insert(0, str(code_root))\n",
    "\n",
    "product_similarity = importlib.import_module(\"product_similarity\")\n",
    "print(\"Loaded product_similarity version:\", getattr(product_similarity, \"__version__\", \"unknown\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T14:16:09.720172Z",
     "iopub.status.busy": "2025-10-15T14:16:09.719829Z",
     "iopub.status.idle": "2025-10-15T14:16:09.725899Z",
     "shell.execute_reply": "2025-10-15T14:16:09.725093Z",
     "shell.execute_reply.started": "2025-10-15T14:16:09.720155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build nice_chunks.json if missing\n",
    "from pathlib import Path\n",
    "\n",
    "nice_path = code_root / \"data\" / \"nice_chunks.json\"\n",
    "if not nice_path.exists():\n",
    "    print(\"nice_chunks.json missing -> attempt to build from data_nice_cls\")\n",
    "    tools_script = code_root / \"tools\" / \"merge_nice_cls.py\"\n",
    "    if not tools_script.exists():\n",
    "        raise RuntimeError(\"merge_nice_cls.py not found in repo/tools\")\n",
    "    import runpy\n",
    "    runpy.run_path(str(tools_script))\n",
    "else:\n",
    "    print(\"Found:\", nice_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T14:16:09.727281Z",
     "iopub.status.busy": "2025-10-15T14:16:09.726926Z",
     "iopub.status.idle": "2025-10-15T14:16:09.736428Z",
     "shell.execute_reply": "2025-10-15T14:16:09.735714Z",
     "shell.execute_reply.started": "2025-10-15T14:16:09.727263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"NV_API_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T14:16:09.737693Z",
     "iopub.status.busy": "2025-10-15T14:16:09.737416Z",
     "iopub.status.idle": "2025-10-15T14:16:09.747135Z",
     "shell.execute_reply": "2025-10-15T14:16:09.746337Z",
     "shell.execute_reply.started": "2025-10-15T14:16:09.737670Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Toggles\n",
    "USE_MODEL = False  # set True to use HF model id below\n",
    "MODEL_ID = \"google/flan-t5-base\"  # change model as needed\n",
    "DEVICE = 0  # -1 CPU, 0 GPU\n",
    "\n",
    "# Use OpenAI-compatible Chat API (e.g., NVIDIA) instead of HF\n",
    "USE_CHAT_API = True\n",
    "CHAT_API_BASE_URL = \"https://integrate.api.nvidia.com/v1\"\n",
    "CHAT_API_MODEL = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n",
    "# Set Kaggle secret NV_API_KEY in notebook Settings -> Add-ons -> Secrets\n",
    "CHAT_API_KEY = os.environ.get(\"NV_API_KEY\")\n",
    "\n",
    "# Optional: provide known NICE class numbers for p1/p2\n",
    "CLASS_1 = '1'  # e.g., \"3\" None\n",
    "CLASS_2 = '1' # e.g., \"16\" None\n",
    "\n",
    "from product_similarity.pipeline import run_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T14:16:09.749711Z",
     "iopub.status.busy": "2025-10-15T14:16:09.749477Z",
     "iopub.status.idle": "2025-10-15T14:16:09.756879Z",
     "shell.execute_reply": "2025-10-15T14:16:09.755824Z",
     "shell.execute_reply.started": "2025-10-15T14:16:09.749693Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Single-run example\n",
    "# p1 = \"chemical products used in the manufacture of plastics and in the photocopying industry\"\n",
    "# p2 = \"chemical additives for detergents\"\n",
    "\n",
    "\n",
    "# # HF model\n",
    "# # res = run_similarity(\n",
    "# #     p1,\n",
    "# #     p2,\n",
    "# #     class_1=CLASS_1,\n",
    "# #     class_2=CLASS_2,\n",
    "# #     model_name=(MODEL_ID if USE_MODEL else None),\n",
    "# #     device=DEVICE,\n",
    "# # )\n",
    "\n",
    "# # NV Model\n",
    "# res = run_similarity(\n",
    "#     p1,\n",
    "#     p2,\n",
    "#     class_1=CLASS_1,\n",
    "#     class_2=CLASS_2,\n",
    "#     model_name=(MODEL_ID if (USE_MODEL and not USE_CHAT_API) else None),\n",
    "#     chat_api_base_url=(CHAT_API_BASE_URL if USE_CHAT_API else None),\n",
    "#     chat_api_key=(CHAT_API_KEY if USE_CHAT_API else None),\n",
    "#     chat_api_model=(CHAT_API_MODEL if USE_CHAT_API else None),\n",
    "#     device=DEVICE,\n",
    "#     max_new_tokens=2048,\n",
    "#     temperature=0.6,\n",
    "#     top_p=0.95,\n",
    "# )\n",
    "\n",
    "# # Show compact summary\n",
    "# print(\"Scores:\", res[\"scores\"])  # may be None values if USE_MODEL=False\n",
    "# print(\"Contexts:\")\n",
    "# for c in res[\"contexts\"]:\n",
    "#     print(\"-\", c.split(\"\\n\")[0])\n",
    "\n",
    "# # Truncated prompt preview\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T14:16:09.758507Z",
     "iopub.status.busy": "2025-10-15T14:16:09.757712Z",
     "iopub.status.idle": "2025-10-15T14:16:09.768706Z",
     "shell.execute_reply": "2025-10-15T14:16:09.767844Z",
     "shell.execute_reply.started": "2025-10-15T14:16:09.758490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(\"\\nPrompt preview:\\n\", res[\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T14:16:09.769697Z",
     "iopub.status.busy": "2025-10-15T14:16:09.769505Z",
     "iopub.status.idle": "2025-10-15T14:16:10.107182Z",
     "shell.execute_reply": "2025-10-15T14:16:10.106257Z",
     "shell.execute_reply.started": "2025-10-15T14:16:09.769681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Batch evaluation from CSV (optional)\n",
    "# Expect CSV with headers: p1,p2[,class1,class2]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json as _json\n",
    "\n",
    "# Prefer 75_samples if available, else fall back to 100_samples\n",
    "csv_75 = code_root / \"data\" / \"75_samples.csv\"\n",
    "csv_100 = code_root / \"data\" / \"100_samples.csv\"\n",
    "csv_path = csv_75 if csv_75.exists() else csv_100\n",
    "\n",
    "if not csv_path.exists():\n",
    "    print(\"CSV not found:\", csv_path)\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    label_col = next((c for c in df.columns if c.strip().lower() == \"level of similarity\"), None)\n",
    "    print(\"Loaded\", len(df), \"rows from:\", csv_path)\n",
    "    data_prepared = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-15T14:17:57.343Z",
     "iopub.execute_input": "2025-10-15T14:16:20.769875Z",
     "iopub.status.busy": "2025-10-15T14:16:20.769370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if data_prepared:\n",
    "    out_rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        p1 = str(row.get(\"Item1\", row.iloc[0]))\n",
    "        p2 = str(row.get(\"Item2\", row.iloc[1]))\n",
    "        c1 = row.get(\"class1\", CLASS_1)\n",
    "        c2 = row.get(\"class2\", CLASS_2)\n",
    "\n",
    "        res = run_similarity(\n",
    "            p1,\n",
    "            p2,\n",
    "            class_1=c1,\n",
    "            class_2=c2,\n",
    "            model_name=(MODEL_ID if (USE_MODEL and not USE_CHAT_API) else None),\n",
    "            chat_api_base_url=(CHAT_API_BASE_URL if USE_CHAT_API else None),\n",
    "            chat_api_key=(CHAT_API_KEY if USE_CHAT_API else None),\n",
    "            chat_api_model=(CHAT_API_MODEL if USE_CHAT_API else None),\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        out = {\n",
    "            \"p1\": p1,\n",
    "            \"p2\": p2,\n",
    "            \"class1\": c1,\n",
    "            \"class2\": c2,\n",
    "            \"nature\": res[\"scores\"].get(\"nature\"),\n",
    "            \"purpose\": res[\"scores\"].get(\"purpose\"),\n",
    "            \"overall\": res[\"scores\"].get(\"overall\"),\n",
    "        }\n",
    "\n",
    "        if label_col and label_col in row:\n",
    "            out[\"label\"] = row[label_col]\n",
    "        out_rows.append(out)\n",
    "        \n",
    "    out_df = pd.DataFrame(out_rows)\n",
    "\n",
    "    # Create explicit 'pred' column from 'overall' (nullable Int)\n",
    "    out_df[\"pred\"] = pd.to_numeric(out_df[\"overall\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Metrics based on label (Level of similarity: integer 0..4)\n",
    "    if \"label\" in out_df.columns:\n",
    "        valid = out_df[\"overall\"].notna() & out_df[\"label\"].notna()\n",
    "        n_eval = int(valid.sum())\n",
    "        if n_eval > 0:\n",
    "            pred = out_df.loc[valid, \"overall\"].astype(int)\n",
    "            label = out_df.loc[valid, \"label\"].astype(int)\n",
    "            accuracy_exact = float((pred == label).mean())\n",
    "            mse = float(np.mean((pred - label) ** 2))\n",
    "        else:\n",
    "            accuracy_exact = 0.0\n",
    "            mse = None\n",
    "    else:\n",
    "        accuracy_exact = None\n",
    "        mse = None\n",
    "        n_eval = 0\n",
    "\n",
    "    # Save outputs\n",
    "    out_path = Path(\"/kaggle/working/batch_results.csv\")\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "\n",
    "    metrics = {\"accuracy_exact\": accuracy_exact, \"mse\": mse, \"n_eval\": n_eval}\n",
    "    metrics_path = Path(\"/kaggle/working/metrics.json\")\n",
    "    metrics_path.write_text(_json.dumps(metrics, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(\"Saved:\", out_path)\n",
    "    print(\"Metrics:\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8498060,
     "sourceId": 13394037,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8498128,
     "sourceId": 13394411,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
